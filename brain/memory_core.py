import os
import shutil
import time
from langchain_community.document_loaders import PyMuPDFLoader, TextLoader, DirectoryLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma

# ==========================================
# üß† CONFIGURA√á√ÉO DA MEM√ìRIA (CORTEX)
# ==========================================
KNOWLEDGE_DIR = "knowledge_base"
PROCESSED_DIR = os.path.join(KNOWLEDGE_DIR, "documentos_lidos") 
DB_DIR = "chroma_db_permanent" 

EMBEDDING_MODEL = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

def aprender_documentos():
    """
    L√™ arquivos, valida conte√∫do, salva na mem√≥ria e arquiva.
    """
    print(f"üß† [MEM√ìRIA] Verificando Caixa de Entrada '{KNOWLEDGE_DIR}'...")
    
    if not os.path.exists(KNOWLEDGE_DIR):
        os.makedirs(KNOWLEDGE_DIR)
    if not os.path.exists(PROCESSED_DIR):
        os.makedirs(PROCESSED_DIR)

    # 1. Carregadores
    loaders = [
        DirectoryLoader(KNOWLEDGE_DIR, glob="*.pdf", loader_cls=PyMuPDFLoader),
        DirectoryLoader(KNOWLEDGE_DIR, glob="*.txt", loader_cls=TextLoader)
    ]
    
    documents = []
    files_found = []

    for loader in loaders:
        try:
            docs = loader.load()
            for doc in docs:
                # --- NOVO: FILTRO DE CONTE√öDO VAZIO ---
                if doc.page_content and len(doc.page_content.strip()) > 10:
                    documents.append(doc)
                    source = doc.metadata.get('source')
                    if source and source not in files_found:
                        files_found.append(source)
                else:
                    print(f"‚ö†Ô∏è Aviso: P√°gina vazia ou imagem ignorada em: {doc.metadata.get('source')}")
                    
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao ler arquivo: {e}")

    if not documents:
        print("‚úÖ Nenhum texto v√°lido encontrado para processar.")
        return

    print(f"üìö [MEM√ìRIA] Processando {len(files_found)} arquivos com texto leg√≠vel...")

    # 2. Quebrar em Peda√ßos
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    chunks = text_splitter.split_documents(documents)
    
    # --- NOVO: VERIFICA√á√ÉO FINAL ANTES DO BANCO ---
    if not chunks:
        print("‚ùå Erro: O processamento gerou 0 fragmentos. Os arquivos podem ser imagens/scans.")
        return

    print(f"üß© [MEM√ìRIA] Gerando {len(chunks)} fragmentos neurais...")

    # 3. Salvar no ChromaDB
    try:
        vector_db = Chroma.from_documents(
            documents=chunks,
            embedding=EMBEDDING_MODEL,
            persist_directory=DB_DIR
        )
        print("üíæ [SUCESSO] Conhecimento gravado no C√≥rtex!")
        
        # 4. ARQUIVAMENTO
        print("üì¶ [ORGANIZA√á√ÉO] Arquivando documentos...")
        
        for file_path in files_found:
            try:
                file_name = os.path.basename(file_path)
                destination = os.path.join(PROCESSED_DIR, file_name)
                
                if os.path.exists(destination):
                    timestamp = int(time.time())
                    name, ext = os.path.splitext(file_name)
                    destination = os.path.join(PROCESSED_DIR, f"{name}_{timestamp}{ext}")
                
                shutil.move(file_path, destination)
                print(f"   -> Movido: {file_name}")
                
            except Exception as move_err:
                print(f"   ‚ö†Ô∏è Erro ao mover {file_name}: {move_err}")
        
    except Exception as e:
        print(f"‚ùå Erro Cr√≠tico ao gravar no banco: {e}")

def buscar_memoria(query, k=3):
    if not os.path.exists(DB_DIR):
        return []

    vector_db = Chroma(persist_directory=DB_DIR, embedding_function=EMBEDDING_MODEL)
    results = vector_db.similarity_search(query, k=k)
    return results

if __name__ == "__main__":
    print("--- INICIANDO ROTINA DE APRENDIZADO ---")
    aprender_documentos()